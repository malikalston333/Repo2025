{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7f9be3",
   "metadata": {},
   "source": [
    "Extract Data 1.1 \n",
    "\n",
    "For “Credit Card System,” create a Python and PySpark SQL program to read/extract the following JSON files according to the specifications found in the mapping document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982b626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import neccessary Pyspark modules\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "# Create or retrieve an existing SparkSession.\n",
    "# This is the entry point to use DataFrame and SQL functionality in PySpark.\n",
    "# The 'appName' is used to name your Spark application, which helps when monitoring jobs in Spark UI.\n",
    "os.environ[\"HADOOP_OPTS\"] = \"-Djava.library.path=\"\n",
    "spark.stop()\n",
    "spark = SparkSession.builder.appName('Credit Card Data Loader').config(\"spark.hadoop.disable.native.lib\", \"true\").getOrCreate()\n",
    "# Load the 'cdw_sapp_branch.json' JSON file into a DataFrame.\n",
    "# Load the 'cdw_sapp_credit.json' JSON file into a DataFrame.\n",
    "# Load the 'cdw_sapp_customer.json' JSON file into a DataFrame.\n",
    "# The 'option(\"multiline\", \"true\")' tells Spark to handle JSON entries that span multiple lines.\n",
    "# This is useful when each record is formatted across several lines for readability.\n",
    "df_branch = spark.read.option(\"multiline\", \"true\").json(r\"C:\\Users\\malik.alston\\Desktop\\Data\\Credit Card Dataset Overview\\cdw_sapp_branch.json\")\n",
    "df_cc = spark.read.option(\"multiline\", \"true\").json(r\"C:\\Users\\malik.alston\\Desktop\\Data\\Credit Card Dataset Overview\\cdw_sapp_credit.json\")\n",
    "df_customer = spark.read.option(\"multiline\", \"true\").json(r\"C:\\Users\\malik.alston\\Desktop\\Data\\Credit Card Dataset Overview\\cdw_sapp_customer.json\")\n",
    "# The below lines are currently commented out but can be used to visually inspect\n",
    "# The contents of each DataFrame. They display the top 20 rows by default in a tabular format.\n",
    "# df_customer.show()\n",
    "# df_branch.show()\n",
    "# df_cc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088517f3",
   "metadata": {},
   "source": [
    "Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f881acba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import initcap, lower, concat_ws, format_string, col, lpad, lit, concat, when\n",
    "# initcap()\tCapitalize first letter of each word, lower() Convert string to lowercase, concat_ws()\tConcatenate with separator, format_string()\tString formatting\n",
    "# col()\tReference to a column, lpad() Left-pad a string, lit()\tAdd a constant/literal column, concat()\tConcatenate columns (no separator), when() Conditional logic\n",
    "df_customer = df_customer.withColumn(\"FIRST_NAME\", initcap(\"FIRST_NAME\"))\n",
    "df_customer = df_customer.withColumn(\"LAST_NAME\", initcap(\"LAST_NAME\"))\n",
    "df_customer = df_customer.withColumn(\"MIDDLE_NAME\", lower(\"MIDDLE_NAME\"))\n",
    "df_customer = df_customer.withColumn(\"ADDRESS\", concat_ws(\",\", \"STREET_NAME\", \"APT_NO\"))\n",
    "df_customer = df_customer.withColumn(\"CUST_PHONE\",concat(lit(\"(XXX)\"),col(\"CUST_PHONE\").substr(1, 3),lit(\"-\"),col(\"CUST_PHONE\").substr(4, 4)))\n",
    "\n",
    "df_branch = df_branch.withColumn(\"BRANCH_PHONE\",concat(lit(\"(XXX)\"),col(\"BRANCH_PHONE\").substr(1, 3),lit(\"-\"),col(\"BRANCH_PHONE\").substr(4, 4)))\n",
    "df_branch = df_branch.withColumn(\"BRANCH_ZIP\", when(col(\"BRANCH_ZIP\").isNull(), lit(\"99999\")).otherwise(col(\"BRANCH_ZIP\")))\n",
    "\n",
    "df_cc = df_cc.withColumn(\"TIMEID\", format_string(\"%04d%02d%02d\", col(\"YEAR\"), col(\"MONTH\"), col(\"DAY\")))\n",
    "#df_customer.show()\n",
    "#df_branch.show()\n",
    "#df_cc.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b4457",
   "metadata": {},
   "source": [
    "Load Data 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "261fca16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DataFrames transferred to MySQL.\n"
     ]
    }
   ],
   "source": [
    "mysql_url = \"jdbc:mysql://localhost:3306/creditcard_capstone\"\n",
    "\n",
    "mysql_config = {\n",
    "    \"user\": \"root\",\n",
    "    \"password\": \"password\",\n",
    "    \"driver\": \"com.mysql.cj.jdbc.Driver\"\n",
    "}\n",
    "\n",
    "df_customer.write.jdbc(\n",
    "    url=mysql_url,\n",
    "    table=\"CDW_SAPP_CUSTOMER\",\n",
    "    mode=\"append\",  # use 'append' if you want to preserve existing data\n",
    "    properties=mysql_config\n",
    ")\n",
    "\n",
    "df_branch.write.jdbc(\n",
    "    url=mysql_url,\n",
    "    table=\"CDW_SAPP_BRANCH\",\n",
    "    mode=\"append\",\n",
    "    properties=mysql_config\n",
    ")\n",
    "\n",
    "df_cc.write.jdbc(\n",
    "    url=mysql_url,\n",
    "    table=\"CDW_SAPP_CREDIT_CARD\",\n",
    "    mode=\"append\",\n",
    "    properties=mysql_config\n",
    ")\n",
    "\n",
    "print(\"All DataFrames transferred to MySQL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbc02ce",
   "metadata": {},
   "source": [
    "df_customer.printSchema()\n",
    "df_branch.printSchema()\n",
    "df_cc.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16097aa",
   "metadata": {},
   "source": [
    "CREATE TABLE CDW_SAPP_CUSTOMER (\n",
    "    APT_NO VARCHAR(10),\n",
    "    CREDIT_CARD_NO VARCHAR(20),\n",
    "    CUST_CITY VARCHAR(50),\n",
    "    CUST_COUNTRY VARCHAR(50),\n",
    "    CUST_EMAIL VARCHAR(100),\n",
    "    CUST_PHONE VARCHAR(20),\n",
    "    CUST_STATE VARCHAR(50),\n",
    "    CUST_ZIP VARCHAR(10),\n",
    "    FIRST_NAME VARCHAR(50),\n",
    "    LAST_NAME VARCHAR(50),\n",
    "    LAST_UPDATED VARCHAR(50),\n",
    "    MIDDLE_NAME VARCHAR(50),\n",
    "    SSN BIGINT PRIMARY KEY,\n",
    "    STREET_NAME VARCHAR(100),\n",
    "    ADDRESS VARCHAR(200) NOT NULL\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2451fc8",
   "metadata": {},
   "source": [
    "CREATE TABLE CDW_SAPP_BRANCH (\n",
    "    BRANCH_CITY VARCHAR(50),\n",
    "    BRANCH_CODE BIGINT PRIMARY KEY,\n",
    "    BRANCH_NAME VARCHAR(100),\n",
    "    BRANCH_PHONE VARCHAR(20),\n",
    "    BRANCH_STATE VARCHAR(50),\n",
    "    BRANCH_STREET VARCHAR(100),\n",
    "    BRANCH_ZIP VARCHAR(10),\n",
    "    LAST_UPDATED VARCHAR(50)\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee29542d",
   "metadata": {},
   "source": [
    "CREATE TABLE CDW_SAPP_CREDIT_CARD (\n",
    "    BRANCH_CODE BIGINT,\n",
    "    CREDIT_CARD_NO VARCHAR(20),\n",
    "    CUST_SSN BIGINT,\n",
    "    DAY INT,\n",
    "    MONTH INT,\n",
    "    TRANSACTION_ID BIGINT PRIMARY KEY,\n",
    "    TRANSACTION_TYPE VARCHAR(50),\n",
    "    TRANSACTION_VALUE DOUBLE,\n",
    "    YEAR INT,\n",
    "    TIMEID VARCHAR(20) NOT NULL\n",
    ");\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
