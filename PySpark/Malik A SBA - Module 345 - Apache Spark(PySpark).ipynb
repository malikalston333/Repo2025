{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "419ebdd5",
   "metadata": {},
   "source": [
    "1.1: \n",
    "\n",
    "Load/Read the CompanyABC Stock (CompanyABC stock.csv) data into the SparkSQL DataFrame [ hint read() ]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f640d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary Pyspark modules\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import mean,avg,max,min\n",
    "# Create a Spark session with a session name relevant to the task/project\n",
    "spark = SparkSession.builder.appName(\"CompanyABC\").getOrCreate()\n",
    "# Reading/loading the dataset from csv file\n",
    "abcdf = spark.read.load(r\"C:\\Users\\malik.alston\\Desktop\\Data\\CompanyABC_stock.csv\", format = \"csv\", header = True, inferschema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44c48c6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abcdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91130301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|summary|              Open|             High|              Low|            Close|           Volume|        Adj Close|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "|  count|              1258|             1258|             1258|             1258|             1258|             1258|\n",
      "|   mean| 72.35785375357709|72.83938807631165| 71.9186009594594|72.38844998012726|8222093.481717011|67.23883848728146|\n",
      "| stddev|  6.76809024470826|6.768186808159218|6.744075756255496|6.756859163732991|  4519780.8431556|6.722609449996857|\n",
      "|    min|56.389998999999996|        57.060001|        56.299999|        56.419998|          2094900|        50.363689|\n",
      "|    max|         90.800003|        90.970001|            89.25|        90.470001|         80898100|84.91421600000001|\n",
      "+-------+------------------+-----------------+-----------------+-----------------+-----------------+-----------------+\n",
      "\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abcdf.columns # Displays a list of all column names in the dataframe\n",
    "abcdf.printSchema() # Print the schema in tree format\n",
    "abcdf.describe().show()\n",
    "abcdf.show() # Display data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c5febe",
   "metadata": {},
   "source": [
    "1.2: \n",
    "\n",
    "print first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bdc057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Date=datetime.date(2012, 1, 3), Open=59.970001, High=61.060001, Low=59.869999, Close=60.330002, Volume=12668800, Adj Close=52.619234999999996),\n",
       " Row(Date=datetime.date(2012, 1, 4), Open=60.209998999999996, High=60.349998, Low=59.470001, Close=59.709998999999996, Volume=9593300, Adj Close=52.078475),\n",
       " Row(Date=datetime.date(2012, 1, 5), Open=59.349998, High=59.619999, Low=58.369999, Close=59.419998, Volume=12768200, Adj Close=51.825539),\n",
       " Row(Date=datetime.date(2012, 1, 6), Open=59.419998, High=59.450001, Low=58.869999, Close=59.0, Volume=8069400, Adj Close=51.45922),\n",
       " Row(Date=datetime.date(2012, 1, 9), Open=59.029999, High=59.549999, Low=58.919998, Close=59.18, Volume=6679300, Adj Close=51.616215000000004)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abcdf.head(5) # Display top 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a8b70b",
   "metadata": {},
   "source": [
    "1.3: \n",
    "\n",
    "Create a new DataFrame column called “HV Ratio,” which will stimulate the ratio of the High price versus the total Volume of stock that was traded for a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0811bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            HV Ratio|\n",
      "+--------------------+\n",
      "|4.819714653321546E-6|\n",
      "|6.290848613094555E-6|\n",
      "|4.669412994783916E-6|\n",
      "|7.367338463826307E-6|\n",
      "|8.915604778943901E-6|\n",
      "|8.644477436914568E-6|\n",
      "|9.351828421515645E-6|\n",
      "| 8.29141562102703E-6|\n",
      "|7.712212102001476E-6|\n",
      "|7.071764823529412E-6|\n",
      "|1.015495466386981E-5|\n",
      "|6.576354146362592...|\n",
      "| 5.90145296180676E-6|\n",
      "|8.547679455011844E-6|\n",
      "|8.420709512685392E-6|\n",
      "|1.041448341728929...|\n",
      "|8.316075414862431E-6|\n",
      "|9.721183814992126E-6|\n",
      "|8.029436027707578E-6|\n",
      "|6.307432259386365E-6|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abcdf.withColumn(\"HV Ratio\", abcdf[\"High\"] / abcdf[\"Volume\"]).select('HV Ratio').show() # Create new column named HV Ratio which displays the ratio of High over volume"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b74977",
   "metadata": {},
   "source": [
    "1.4: \n",
    "\n",
    "Find out on what day the stock price was the highest. (Hint: use the High column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ab743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|      Date|max(High)|\n",
      "+----------+---------+\n",
      "|2012-04-17|61.950001|\n",
      "|2013-01-22|69.650002|\n",
      "|2013-03-26|75.089996|\n",
      "|2013-05-21|    78.18|\n",
      "|2013-09-09|73.650002|\n",
      "|2014-09-26|    76.57|\n",
      "|2014-11-12|79.440002|\n",
      "|2015-03-09|83.339996|\n",
      "|2015-05-19|78.360001|\n",
      "|2016-03-01|66.889999|\n",
      "|2012-07-17|73.099998|\n",
      "|2013-09-19|76.529999|\n",
      "|2015-03-06|83.099998|\n",
      "|2016-04-25|     69.5|\n",
      "|2014-08-01|73.879997|\n",
      "|2015-04-09|81.389999|\n",
      "|2015-09-02|64.940002|\n",
      "|2015-12-22|60.700001|\n",
      "|2016-05-03|     67.5|\n",
      "|2016-07-26|    74.07|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abcdf.groupby('Date').agg(max('High')).show()\n",
    "# abcdf.select('Date', 'High').groupby('Date').max().show() alternate way"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a871b20a",
   "metadata": {},
   "source": [
    "1.5: \n",
    "\n",
    "What is the average (mean) closing price? (Hint: Use the Close column.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "985454cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|       avg(Close)|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abcdf.select(avg(\"Close\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8717961",
   "metadata": {},
   "source": [
    "1.6: \n",
    "\n",
    "What are the maximum and minimum volumes of stock traded? (Hint: Use the Volume column.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e4595ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|   80898100|    2094900|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "abcdf.select(max('Volume'), min('Volume')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6932476",
   "metadata": {},
   "source": [
    "1.7: \n",
    "\n",
    "For how many days was the closing value less than 70 dollars? (Hint: Use the count() method.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7ca22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abcdf.filter(abcdf['Close'] < 70).count() # Displays the column Close that is under $70 then counts them using the count function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3369b809",
   "metadata": {},
   "source": [
    "1.8: \n",
    "\n",
    "What percentage of the time was the High greater than 80 dollars?\n",
    " (Hint: (Number of Days High>80)/(Total Days in the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444d2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of the time that was greater than $80 was 9.14%\n"
     ]
    }
   ],
   "source": [
    "days = abcdf.select(\"Date\").count() # Counts total number of days\n",
    "high = abcdf.filter(abcdf['High'] > 80).count() # Counts times the high was greater than 80 dollaars\n",
    "\n",
    "number_of_days  = high / days # Divide to get percentage\n",
    "\n",
    "print(f\"The percentage of the time that was greater than $80 was {number_of_days:.2%}\") # Gets the percentage by moving the decimal twice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812f6686",
   "metadata": {},
   "source": [
    "1.10: \n",
    "\n",
    "Load/Write CompanyABC stock.csv file data into CompanyABC_DB database from the SparkSQL Dataframe. You can specify any table name for that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608bccf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|59.549999|58.919998|             59.18| 6679300|51.616215000000004|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder .master(\"local[*]\").appName(\"CompanyABC Stock Loader\").getOrCreate()\n",
    "\n",
    "# Load the CSV into a DataFrame\n",
    "df = spark.read.csv(\"C:/Users/malik.alston/Desktop/Data/CompanyABC_stock.csv\",header=True,inferSchema=True)\n",
    "\n",
    "df.show(5)\n",
    "\n",
    "# Write DataFrame to MySQL table named `company_stock_data`\n",
    "df.write.format(\"jdbc\").options(driver=\"com.mysql.cj.jdbc.Driver\",\\\n",
    "    user=\"root\",\\\n",
    "    password=\"password\",\\\n",
    "    url=\"jdbc:mysql://localhost:3306/CompanyABC_DB\",\\\n",
    "    dbtable=\"company_stock_data\").mode(\"overwrite\").save()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb4f66f",
   "metadata": {},
   "source": [
    "Section Two: CompanyABC Sales Data\n",
    "\n",
    "2.1: Load/Read both CompanyABC sales datasets (Sales_April_2019.csv and Sales_February_2019.csv) into a single SparkSQL DataFrame ( hint read() )."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f927e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "|Order ID|             Product|Quantity Ordered|Price Each|    Order Date|    Purchase Address|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "|  150502|              iPhone|               1|     700.0|02/18/19 01:35|866 Spruce St, Po...|\n",
      "|  150503|AA Batteries (4-p...|               1|      3.84|02/13/19 07:24|18 13th St, San F...|\n",
      "|  150504|27in 4K Gaming Mo...|               1|    389.99|02/18/19 09:46|52 6th St, New Yo...|\n",
      "|  150505|Lightning Chargin...|               1|     14.95|02/02/19 16:47|129 Cherry St, At...|\n",
      "|  150506|AA Batteries (4-p...|               2|      3.84|02/28/19 20:32|548 Lincoln St, S...|\n",
      "|  150507|Lightning Chargin...|               1|     14.95|02/24/19 18:50|387 12th St, Aust...|\n",
      "|  150508|AA Batteries (4-p...|               1|      3.84|02/21/19 19:26|622 Center St, Sa...|\n",
      "|  150509|Apple Airpods Hea...|               1|     150.0|02/26/19 19:53|921 6th St, Seatt...|\n",
      "|  150510|USB-C Charging Cable|               1|     11.95|02/17/19 21:48|451 2nd St, Los A...|\n",
      "|  150511|USB-C Charging Cable|               1|     11.95|02/22/19 07:36|689 River St, San...|\n",
      "|  150512|Bose SoundSport H...|               1|     99.99|02/17/19 18:29|198 Center St, Lo...|\n",
      "|  150513|Bose SoundSport H...|               1|     99.99|02/25/19 20:49|777 Spruce St, Lo...|\n",
      "|  150514|    27in FHD Monitor|               1|    149.99|02/03/19 00:21|723 Wilson St, Lo...|\n",
      "|  150515|Apple Airpods Hea...|               1|     150.0|02/18/19 14:53|101 13th St, New ...|\n",
      "|  150516|Lightning Chargin...|               1|     14.95|02/20/19 12:29|303 Sunset St, At...|\n",
      "|  150517|    Wired Headphones|               1|     11.99|02/08/19 12:57|471 13th St, San ...|\n",
      "|  150518|  Macbook Pro Laptop|               1|    1700.0|02/26/19 12:38|847 10th St, San ...|\n",
      "|  150518|              iPhone|               1|     700.0|02/26/19 12:38|847 10th St, San ...|\n",
      "|  150519|    Wired Headphones|               1|     11.99|02/23/19 13:25|111 Hill St, Dall...|\n",
      "|  150520|AA Batteries (4-p...|               2|      3.84|02/27/19 14:39|512 Church St, Da...|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('Sectiontwo').getOrCreate()\n",
    "\n",
    "df_multi = spark.read.csv([r\"C:\\Users\\malik.alston\\Desktop\\Data\\Sales_February_2019.csv\", r\"C:\\Users\\malik.alston\\Desktop\\Data\\my_file.txt\"], header=True,inferSchema=True)\n",
    "\n",
    "df_multi.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de73ae3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Order ID: string (nullable = true)\n",
      " |-- Product: string (nullable = true)\n",
      " |-- Quantity Ordered: integer (nullable = true)\n",
      " |-- Price Each: double (nullable = true)\n",
      " |-- Order Date: string (nullable = true)\n",
      " |-- Purchase Address: string (nullable = true)\n",
      "\n",
      "+-------+------------------+------------+------------------+------------------+--------------+--------------------+\n",
      "|summary|          Order ID|     Product|  Quantity Ordered|        Price Each|    Order Date|    Purchase Address|\n",
      "+-------+------------------+------------+------------------+------------------+--------------+--------------------+\n",
      "|  count|             12006|       12004|             11986|             11986|         12004|               12004|\n",
      "|   mean|156250.61338227932|        NULL|1.1230602369431002|182.74150675788204|          NULL|                NULL|\n",
      "| stddev|3322.0752634362825|        NULL|0.4311103873526451|325.54329574605885|          NULL|                NULL|\n",
      "|    min|            150502|20in Monitor|                 1|              2.99|02/01/19 01:51|1 Hill St, Boston...|\n",
      "|    max|          Order ID|      iPhone|                 7|            1700.0|    Order Date|    Purchase Address|\n",
      "+-------+------------------+------------+------------------+------------------+--------------+--------------------+\n",
      "\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "|Order ID|             Product|Quantity Ordered|Price Each|    Order Date|    Purchase Address|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "|  150502|              iPhone|               1|     700.0|02/18/19 01:35|866 Spruce St, Po...|\n",
      "|  150503|AA Batteries (4-p...|               1|      3.84|02/13/19 07:24|18 13th St, San F...|\n",
      "|  150504|27in 4K Gaming Mo...|               1|    389.99|02/18/19 09:46|52 6th St, New Yo...|\n",
      "|  150505|Lightning Chargin...|               1|     14.95|02/02/19 16:47|129 Cherry St, At...|\n",
      "|  150506|AA Batteries (4-p...|               2|      3.84|02/28/19 20:32|548 Lincoln St, S...|\n",
      "|  150507|Lightning Chargin...|               1|     14.95|02/24/19 18:50|387 12th St, Aust...|\n",
      "|  150508|AA Batteries (4-p...|               1|      3.84|02/21/19 19:26|622 Center St, Sa...|\n",
      "|  150509|Apple Airpods Hea...|               1|     150.0|02/26/19 19:53|921 6th St, Seatt...|\n",
      "|  150510|USB-C Charging Cable|               1|     11.95|02/17/19 21:48|451 2nd St, Los A...|\n",
      "|  150511|USB-C Charging Cable|               1|     11.95|02/22/19 07:36|689 River St, San...|\n",
      "|  150512|Bose SoundSport H...|               1|     99.99|02/17/19 18:29|198 Center St, Lo...|\n",
      "|  150513|Bose SoundSport H...|               1|     99.99|02/25/19 20:49|777 Spruce St, Lo...|\n",
      "|  150514|    27in FHD Monitor|               1|    149.99|02/03/19 00:21|723 Wilson St, Lo...|\n",
      "|  150515|Apple Airpods Hea...|               1|     150.0|02/18/19 14:53|101 13th St, New ...|\n",
      "|  150516|Lightning Chargin...|               1|     14.95|02/20/19 12:29|303 Sunset St, At...|\n",
      "|  150517|    Wired Headphones|               1|     11.99|02/08/19 12:57|471 13th St, San ...|\n",
      "|  150518|  Macbook Pro Laptop|               1|    1700.0|02/26/19 12:38|847 10th St, San ...|\n",
      "|  150518|              iPhone|               1|     700.0|02/26/19 12:38|847 10th St, San ...|\n",
      "|  150519|    Wired Headphones|               1|     11.99|02/23/19 13:25|111 Hill St, Dall...|\n",
      "|  150520|AA Batteries (4-p...|               2|      3.84|02/27/19 14:39|512 Church St, Da...|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_multi.columns\n",
    "df_multi.printSchema()\n",
    "df_multi.describe().show()\n",
    "df_multi.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeacaa2",
   "metadata": {},
   "source": [
    "2.2.\n",
    "\n",
    " If you use the above command on the sales dataset, you will notice that each Order has “Price Each” and “Quantity Ordered” columns, but the “Total Price” is missing.  See below:\n",
    "\n",
    "Now, create a new Spark DataFrame column called “Total price” and find the “Total Price” of the Order for the combined sales file as shown in the screenshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f523c791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+----------------+----------+--------------+--------------------+-----------+\n",
      "|Order ID|             Product|Quantity Ordered|Price Each|    Order Date|    Purchase Address|Total Price|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+-----------+\n",
      "|  150502|              iPhone|               1|     700.0|02/18/19 01:35|866 Spruce St, Po...|      700.0|\n",
      "|  150503|AA Batteries (4-p...|               1|      3.84|02/13/19 07:24|18 13th St, San F...|       3.84|\n",
      "|  150504|27in 4K Gaming Mo...|               1|    389.99|02/18/19 09:46|52 6th St, New Yo...|     389.99|\n",
      "|  150505|Lightning Chargin...|               1|     14.95|02/02/19 16:47|129 Cherry St, At...|      14.95|\n",
      "|  150506|AA Batteries (4-p...|               2|      3.84|02/28/19 20:32|548 Lincoln St, S...|       7.68|\n",
      "|  150507|Lightning Chargin...|               1|     14.95|02/24/19 18:50|387 12th St, Aust...|      14.95|\n",
      "|  150508|AA Batteries (4-p...|               1|      3.84|02/21/19 19:26|622 Center St, Sa...|       3.84|\n",
      "|  150509|Apple Airpods Hea...|               1|     150.0|02/26/19 19:53|921 6th St, Seatt...|      150.0|\n",
      "|  150510|USB-C Charging Cable|               1|     11.95|02/17/19 21:48|451 2nd St, Los A...|      11.95|\n",
      "|  150511|USB-C Charging Cable|               1|     11.95|02/22/19 07:36|689 River St, San...|      11.95|\n",
      "|  150512|Bose SoundSport H...|               1|     99.99|02/17/19 18:29|198 Center St, Lo...|      99.99|\n",
      "|  150513|Bose SoundSport H...|               1|     99.99|02/25/19 20:49|777 Spruce St, Lo...|      99.99|\n",
      "|  150514|    27in FHD Monitor|               1|    149.99|02/03/19 00:21|723 Wilson St, Lo...|     149.99|\n",
      "|  150515|Apple Airpods Hea...|               1|     150.0|02/18/19 14:53|101 13th St, New ...|      150.0|\n",
      "|  150516|Lightning Chargin...|               1|     14.95|02/20/19 12:29|303 Sunset St, At...|      14.95|\n",
      "|  150517|    Wired Headphones|               1|     11.99|02/08/19 12:57|471 13th St, San ...|      11.99|\n",
      "|  150518|  Macbook Pro Laptop|               1|    1700.0|02/26/19 12:38|847 10th St, San ...|     1700.0|\n",
      "|  150518|              iPhone|               1|     700.0|02/26/19 12:38|847 10th St, San ...|      700.0|\n",
      "|  150519|    Wired Headphones|               1|     11.99|02/23/19 13:25|111 Hill St, Dall...|      11.99|\n",
      "|  150520|AA Batteries (4-p...|               2|      3.84|02/27/19 14:39|512 Church St, Da...|       7.68|\n",
      "+--------+--------------------+----------------+----------+--------------+--------------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_total_price = df_multi.withColumn(\"Total Price\", df_multi[\"Price Each\"] * df_multi[\"Quantity Ordered\"]) # Created new column called Total Price which comes from multiplying 2 other columns \n",
    "df_total_price.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac14f4d5",
   "metadata": {},
   "source": [
    "2.3:\n",
    "\n",
    " Load/Write sales data from the SparkSQL DataFrame into CompanyABC_DB database. You can specify any name for the table. Remember, “Total price” must be recorded. Your result will look similar/closer to the screenshot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a50173e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_price.write.format(\"jdbc\").options(driver=\"com.mysql.cj.jdbc.Driver\",\\\n",
    "    user=\"root\",\\\n",
    "    password=\"password\",\\\n",
    "    url=\"jdbc:mysql://localhost:3306/CompanyABC_DB\",\\ \n",
    "    dbtable=\"sales_data\").mode(\"append\").save() # Created new table called sales_data for mode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
