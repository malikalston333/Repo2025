{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eac6ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "# Import the SparkSession class from the pyspark.sql module\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"Test SQL app\").getOrCreate()\n",
    "# .master(\"local[*]\") \\  - Set the Spark master URL to run locally using all available CPU cores.\n",
    " # .appName(\"Test SQL app\") \\ - Set the name of the Spark application.\n",
    " # .getOrCreate() - Get an existing SparkSession or create a new one if it doesn't exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=spark.read.format(\"jdbc\").options(driver=\"com.mysql.cj.jdbc.Driver\",\\\n",
    "                                     user=\"root\",\\\n",
    "                                     password=\"password\",\\\n",
    "                                     url=\"jdbc:mysql://localhost:3306/classicmodels\",\\\n",
    "                                     dbtable=\"classicmodels.orders\").load()\n",
    "\n",
    "# Read data from a MySQL database into a Spark DataFrame using JDBC\n",
    "# df = spark.read \\\n",
    "#     .format(\"jdbc\") \\                                  # Specify the format as JDBC to read from a relational database\n",
    "#     .options(                                          # Provide connection options:\n",
    "#        driver=\"com.mysql.cj.jdbc.Driver\",              # - The JDBC driver class for MySQL\n",
    "#        user=\"root\",                                    # - Username for connecting to the MySQL database\n",
    "#        password=\"password\",                            # - Password for the MySQL user\n",
    "#        url=\"jdbc:mysql://localhost:3306/classicmodels\",# - JDBC URL including host, port, and database name\n",
    "#        dbtable=\"classicmodels.orders\"                  # - Table to read (schema.table or just table name if default schema)\n",
    "#     ).load()                                           # Load the table data into a Spark DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cfaee55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()  # return number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3cb6515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- orderNumber: integer (nullable = true)\n",
      " |-- orderDate: date (nullable = true)\n",
      " |-- requiredDate: date (nullable = true)\n",
      " |-- shippedDate: date (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- comments: string (nullable = true)\n",
      " |-- customerNumber: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()  # return schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52863cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "|orderNumber| orderDate|requiredDate|shippedDate| status|            comments|customerNumber|\n",
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "|      10100|2003-01-06|  2003-01-13| 2003-01-10|Shipped|                NULL|           363|\n",
      "|      10101|2003-01-09|  2003-01-18| 2003-01-11|Shipped|Check on availabi...|           128|\n",
      "|      10102|2003-01-10|  2003-01-18| 2003-01-14|Shipped|                NULL|           181|\n",
      "|      10103|2003-01-29|  2003-02-07| 2003-02-02|Shipped|                NULL|           121|\n",
      "|      10104|2003-01-31|  2003-02-09| 2003-02-01|Shipped|                NULL|           141|\n",
      "|      10105|2003-02-11|  2003-02-21| 2003-02-12|Shipped|                NULL|           145|\n",
      "|      10106|2003-02-17|  2003-02-24| 2003-02-21|Shipped|                NULL|           278|\n",
      "|      10107|2003-02-24|  2003-03-03| 2003-02-26|Shipped|Difficult to nego...|           131|\n",
      "|      10108|2003-03-03|  2003-03-12| 2003-03-08|Shipped|                NULL|           385|\n",
      "|      10109|2003-03-10|  2003-03-19| 2003-03-11|Shipped|Customer requeste...|           486|\n",
      "|      10110|2003-03-18|  2003-03-24| 2003-03-20|Shipped|                NULL|           187|\n",
      "|      10111|2003-03-25|  2003-03-31| 2003-03-30|Shipped|                NULL|           129|\n",
      "|      10112|2003-03-24|  2003-04-03| 2003-03-29|Shipped|Customer requeste...|           144|\n",
      "|      10113|2003-03-26|  2003-04-02| 2003-03-27|Shipped|                NULL|           124|\n",
      "|      10114|2003-04-01|  2003-04-07| 2003-04-02|Shipped|                NULL|           172|\n",
      "|      10115|2003-04-04|  2003-04-12| 2003-04-07|Shipped|                NULL|           424|\n",
      "|      10116|2003-04-11|  2003-04-19| 2003-04-13|Shipped|                NULL|           381|\n",
      "|      10117|2003-04-16|  2003-04-24| 2003-04-17|Shipped|                NULL|           148|\n",
      "|      10118|2003-04-21|  2003-04-29| 2003-04-26|Shipped|Customer has work...|           216|\n",
      "|      10119|2003-04-28|  2003-05-05| 2003-05-02|Shipped|                NULL|           382|\n",
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()  # return all columns with data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181e3f0",
   "metadata": {},
   "source": [
    "Example 2: \n",
    "\n",
    "Read with a custom query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534ab53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "|orderNumber| orderDate|requiredDate|shippedDate| status|            comments|customerNumber|\n",
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "|      10112|2003-03-24|  2003-04-03| 2003-03-29|Shipped|Customer requeste...|           144|\n",
      "|      10320|2004-11-03|  2004-11-13| 2004-11-07|Shipped|                NULL|           144|\n",
      "|      10326|2004-11-09|  2004-11-16| 2004-11-10|Shipped|                NULL|           144|\n",
      "|      10334|2004-11-19|  2004-11-28|       NULL|On Hold|The outstaniding ...|           144|\n",
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"(select * from orders where customerNumber = 144) as cust\"\n",
    "# Define a SQL subquery that filters the 'orders' table for customerNumber = 144\n",
    "# The subquery is wrapped in parentheses and given an alias ('cust'), which is required by JDBC\n",
    "df=spark.read.format(\"jdbc\").options(driver=\"com.mysql.cj.jdbc.Driver\",\\\n",
    "                                     user=\"root\",\\\n",
    "                                     password=\"password\",\\\n",
    "\n",
    "url=\"jdbc:mysql://localhost:3306/classicmodels\",\\\n",
    "                                     dbtable=query).load()\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06c2e34",
   "metadata": {},
   "source": [
    "Example: 3:\n",
    "\n",
    "Querying Multiple Records from MySQL in PySpark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cccf1c30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "|orderNumber| orderDate|requiredDate|shippedDate| status|            comments|customerNumber|\n",
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "|      10101|2003-01-09|  2003-01-18| 2003-01-11|Shipped|Check on availabi...|           128|\n",
      "|      10230|2004-03-15|  2004-03-24| 2004-03-20|Shipped|Customer very con...|           128|\n",
      "|      10300|2003-10-04|  2003-10-13| 2003-10-09|Shipped|                NULL|           128|\n",
      "|      10323|2004-11-05|  2004-11-12| 2004-11-09|Shipped|                NULL|           128|\n",
      "|      10112|2003-03-24|  2003-04-03| 2003-03-29|Shipped|Customer requeste...|           144|\n",
      "|      10320|2004-11-03|  2004-11-13| 2004-11-07|Shipped|                NULL|           144|\n",
      "|      10326|2004-11-09|  2004-11-16| 2004-11-10|Shipped|                NULL|           144|\n",
      "|      10334|2004-11-19|  2004-11-28|       NULL|On Hold|The outstaniding ...|           144|\n",
      "+-----------+----------+------------+-----------+-------+--------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query=\"(select * from orders where customerNumber = 144 or customerNumber = 128) as cust\"\n",
    "\n",
    "df=spark.read.format(\"jdbc\").options(driver=\"com.mysql.cj.jdbc.Driver\",\\\n",
    "                                     user=\"root\",\\\n",
    "                                     password=\"password\",\\\n",
    "                                     url=\"jdbc:mysql://localhost:3306/classicmodels\",\\\n",
    "                                     dbtable=query \\\n",
    "                                    ).load()\n",
    "df.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
